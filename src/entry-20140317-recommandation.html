$title=Système de recommandation avec Apache Mahout
$description=Retour d'expérience sur la conception d'un système de recommandation avec Apache Mahout
-----
<p>
Sur mon dernier projet, <a
    href="http://www.bluekiwi-software.com/fr/">BlueKiwi</a>, j'ai eu la chance de travailler sur un système de
recommandation.  C'est une plateforme de gestion de contenu, et donc un
utilisateur peut lire ou noter des articles. Le but est donc de recommander des
articles à un utilisateur, en se basant sur ses interactions passées avec la
plateforme. Cela s'appelle du filtrage collaboratif (<i>collaborative
    filtering</i>). Nous allons voir les quelques difficultés rencontrées.
</p>

<p>La librairie choisie est <a href="http://mahout.apache.org/">Apache
    Mahout</a></p>

<h2>La préférence</h2>
<p>
Les algorithmes utilisent une collection de triplets : utilisateur, article,
préférence. La préférence est optionnelle, elle indique la préférence de
l'utilisateur pour l'article. Dans notre cas, le produit étant assez riche, un utilisateur peut effectuer
plusieurs actions sur un article donné (lire, commenter, noter, …). La
préférence est donc calculée avec une fonction <i>maison</i>. Son choix est très important : cela a
 un impact sur l'éparpillement des données (par ex., un utilisateur lit
plus qu'il ne commente). La difficulté est qu'il est impossible de comparer les
performances de différentes fonctions car elles modifient le
jeu de données en entrée.
</p>

<h2>La similarité</h2>
<p>
Le fonctionnement interne de ces algorithmes utilise une fonction de
similarité pour déterminer la distance entre deux utilisateurs. Il en existe
plusieurs, chacune ayant ses avantages et inconvénients.
</p>

<p>
Afin d'illustrer notre propos, voici un exemple de fichier CSV d'entrée au
format (user, item, préférence) :
</p>
<pre class="prettyprint">
1,101,5
1,102,3
1,103,1
2,101,5
2,103,3
2,104,4
2,106,4
</pre>

<h3>Corrélation de Pearson</h3>
<p>
mesure la tendance de deux utilisateurs a évolué ensemble proportionnellement.
</p>
<p>Dans Mahout, pearson et cosine sont identiques car les données sont centrées.
</p>
<p>Calcul : première étape, le centrage des vecteurs. Pour chaque vecteur (i.e.
utilisateur), on soustrait la valeur moyenne :</p>
<pre class="prettyprint">
1,101,5-3=2
1,102,3-3=0
1,103,1-3=-2
2,101,5-4=1
2,103,3-4=-1
2,104,4-4=0
2,106,4-4=0
</pre>
<p>Deuxième étape, le calcul</p>
<table>
    <tr>
        <th></th> 
        <th>x(u1)</th> 
        <th>y(u2)</th> 
        <th>xy</th> 
        <th>x²</th> 
        <th>y²</th> 
    </tr>
    <tr>
        <td>101</td> 
        <td>2</td> 
        <td>0</td> 
        <td>2</td> 
        <td>4</td> 
        <td>0</td> 
    </tr>
    <tr>
        <td>103</td> 
        <td>1</td> 
        <td>-1</td> 
        <td>-1</td> 
        <td>1</td> 
        <td>1</td> 
    </tr>
    <tr>
        <td>Σ</td> 
        <td></td> 
        <td></td> 
        <td>1</td> 
        <td>5</td> 
        <td>1</td> 
    </tr>

</table>
<p>Voici la formule : Σxy/V(Σx²*Σy²), ce qui donne : 1/V5</p>
<p>Inconvénients</p>
<ul>
    <li>Le calcul ne prend pas en compte le nombre de préférences en commun, et
    a donc tendance à éloigner des utilisateurs avec beaucoup de préférences
    communes. Pour pallier à cela, il existe une implémentation pondéré
    (<i>weighted</i>)
    </li>
    <li>Il est impossible de calculer la similarité entre deux utilisateurs
    ayant une seule préférence en commun.
    </li>
</ul>

<h3>Indice de Tanimoto</h3>
<p>
C'est le rapport entre la taille de l'intersection par la taille de l'union. Il
ne prend pas en compte la valeur des préférences.
</p>
<p>
=2/(3+4-2)=2/5
</p>

<h3>Évaluation du système</h3>
<p>Il existe des techniques pour évaluer la qualité d'un système de
recommandation en entrainant l'algorithme sur une partie des données et en
comparant les résultats obtenus avec le reste des données.
</p>
<p>Inconvénients</p>
<ul>
    <li>
    Elle pénalise les algorithmes qui font de bonnes recommandations, mais pour
    lesquelles l'utilisateur n'a pas encore exprimé de préférences.
    </li>
    <li>
    Nous avons eu des divergences entre la qualité ressentie par les utilisateurs
    réelles et celle calculée automatiquement.
    </li>
    <li>
    Cela ne fonctionne pas bien quand les données sont éparpillées. La
    performance du système varie beaucoup entre deux tirs, et parfois elle ne
    peut pas être calculée : <code>java.lang.IllegalArgumentException: Illegal nDCG: NaN</code>
    </li>
</ul>

<h3>Hadoop vs Taste</h3>
<p>
Une des forces de Mahout est de fournir deux implémentations (mono machine et
distribuée avec Hadoop) des mêmes algorithmes.
Cependant, toutes les possibilités ne sont pas disponible en distribuée, comme
par ex. l'<code>IDRescorer</code> que nous utilisons pour filtrer les données à
posteriori.
</p>

<h3>Content based</h3>
<p>Il est aussi possible d'utiliser un système de recommandation pour faire des recommandations
basées sur le contenu. On parle alors de <i>content based</i>. 
Le fichier d'entrée a alors le format : document, term, tf idf.
Le problème avec l'implémentation de Cosine est que deux documents avec un mot
en commun auront une similarité de 1, c'est à dire la valeur maximum.
</p>

<h3>Conclusion</h3>
<p>Lors de la conception d'un système de recommandation, il faut donc penser à
choisir le meilleur algorithme de similarité, penser à l'évaluation de ce
système, penser aux
problèmes du démarrage à froid (<i>cold start</i>). Par ailleurs, l'affichage des
voisinages calculés permet de comprendre les recommandation finales, utile en
phase de debug.</p>

<h3>Liens</h3>
<p>
<a
    href="http://brenocon.com/blog/2012/03/cosine-similarity-pearson-correlation-and-ols-coefficients/">pearson
    and cosine</a>
</p>
